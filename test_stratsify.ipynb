{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11d3bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "from typing import Literal\n",
    "from data import CamVidDataset\n",
    "from stratifiers.kfold import KFoldWrapper\n",
    "from stratifiers.wdes import WDESKFold\n",
    "from stratifiers.ips import IPSKFold\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import csv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08ecc525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(name: str, path: str):\n",
    "    annotation_transform = Lambda(lambda x: torch.as_tensor(np.expand_dims(np.array(x), 0), dtype=torch.int64))\n",
    "    common_args = {'split': 'train', 'image_transform': ToTensor(), 'annotation_transform': annotation_transform}\n",
    "    if name == 'camvid':\n",
    "        return CamVidDataset(path, **common_args)\n",
    "    raise ValueError('Unsupported dataset {}'.format(name))\n",
    "\n",
    "def get_stratifier(method: Literal['random', 'ips', 'wdes'], n_splits):\n",
    "    if method == 'random':\n",
    "        return KFoldWrapper(n_splits=n_splits)\n",
    "    elif method == 'ips':\n",
    "        return IPSKFold(n_splits=n_splits)\n",
    "    elif method == 'wdes':\n",
    "        return WDESKFold(n_splits=n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "798ede69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset('camvid', './dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df279250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset information for stratifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [01:05<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting WDES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:39<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Split log saved to split_log.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stratifier = get_stratifier('wdes', n_splits=10)\n",
    "\n",
    "# Define where to save your split log\n",
    "split_log_path = \"split_log.csv\"\n",
    "\n",
    "# Create CSV header if not exists\n",
    "if not os.path.exists(split_log_path):\n",
    "    with open(split_log_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"fold\", \"split_type\", \"index\"])\n",
    "\n",
    "# Iterate over folds\n",
    "for i, (train_idx, test_idx) in enumerate(stratifier.split(dataset)):\n",
    "    # if i != 0:  # Only process the first fold for demonstration\n",
    "    #     continue\n",
    "\n",
    "    # Append to CSV for this fold\n",
    "    with open(split_log_path, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        # Log train indices\n",
    "        for idx in train_idx:\n",
    "            writer.writerow([i, \"train\", idx])\n",
    "        # Log test indices\n",
    "        for idx in test_idx:\n",
    "            writer.writerow([i, \"test\", idx])\n",
    "\n",
    "print(f\"✅ Split log saved to {split_log_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7385b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train/Val/Test split log saved to split_log.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assign folds: 0–6 for train, 7 for val, 8 for test (example)\n",
    "train_idx = np.concatenate([splits[i][1] for i in range(8)])\n",
    "val_idx   = splits[8][1]\n",
    "test_idx  = splits[9][1]\n",
    "\n",
    "# Log to CSV\n",
    "with open(split_log_path, \"a\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for idx in train_idx:\n",
    "        writer.writerow([\"train\", idx])\n",
    "    for idx in val_idx:\n",
    "        writer.writerow([\"val\", idx])\n",
    "    for idx in test_idx:\n",
    "        writer.writerow([\"test\", idx])\n",
    "\n",
    "print(f\"✅ Train/Val/Test split log saved to {split_log_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a310b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import wasserstein_distance\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1️⃣ Load folds from split_log.csv\n",
    "# -------------------------------------------------------------\n",
    "def load_folds_from_csv(csv_path):\n",
    "    folds = defaultdict(lambda: {\"train\": [], \"test\": []})\n",
    "    with open(csv_path, newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            folds[int(row[\"fold\"])][row[\"split_type\"]].append(int(row[\"index\"]))\n",
    "    for k in folds:\n",
    "        for s in folds[k]:\n",
    "            folds[k][s] = np.array(folds[k][s])\n",
    "\n",
    "    return folds\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2️⃣ Sample Distribution (same as before)\n",
    "# -------------------------------------------------------------\n",
    "def sample_distribution(folds, proportions):\n",
    "    K = len(folds)\n",
    "    N = sum(len(f) for f in folds)\n",
    "    expected = [r * N for r in proportions]\n",
    "    sd = np.mean([abs(len(folds[k]) - expected[k]) for k in range(K)])\n",
    "    return sd\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3️⃣ Pixel Label Distribution (adapted for image-level)\n",
    "# -------------------------------------------------------------\n",
    "def pixel_label_distribution_from_pixel_counts(folds, pixel_counts):\n",
    "    \"\"\"\n",
    "    pixel_counts: np.array [N_images, num_classes]\n",
    "    folds: list of arrays (each with image indices)\n",
    "    \"\"\"\n",
    "    K = len(folds)\n",
    "    C = pixel_counts.shape[1]\n",
    "\n",
    "    total_pixels = pixel_counts.sum()\n",
    "    total_class_counts = pixel_counts.sum(axis=0)\n",
    "    total_ratios = total_class_counts / total_pixels\n",
    "\n",
    "    pl_diffs = []\n",
    "    for c in range(C):\n",
    "        fold_diffs = []\n",
    "        for fold in folds:\n",
    "            fold_class_count = pixel_counts[fold, c].sum()\n",
    "            fold_pixels = pixel_counts[fold, :].sum()\n",
    "            fold_ratio = fold_class_count / fold_pixels\n",
    "            fold_diffs.append(abs(fold_ratio - total_ratios[c]))\n",
    "        pl_diffs.append(np.mean(fold_diffs))\n",
    "    return np.mean(pl_diffs)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4️⃣ Label Wasserstein Distance (adapted for image-level)\n",
    "# -------------------------------------------------------------\n",
    "def label_wasserstein_distance_from_pixel_counts(folds, pixel_counts):\n",
    "    K = len(folds)\n",
    "    C = pixel_counts.shape[1]\n",
    "\n",
    "    # Normalize full dataset distribution\n",
    "    total_class_dist = pixel_counts.sum(axis=0)\n",
    "    total_class_dist /= total_class_dist.sum()\n",
    "    total_cum = np.cumsum(total_class_dist)\n",
    "\n",
    "    lwd_values = []\n",
    "    for fold in folds:\n",
    "        fold_class_dist = pixel_counts[fold].sum(axis=0)\n",
    "        fold_class_dist /= fold_class_dist.sum()\n",
    "        fold_cum = np.cumsum(fold_class_dist)\n",
    "        lwd_values.append(np.sum(np.abs(total_cum - fold_cum)))\n",
    "    return np.mean(lwd_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9592f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_stratification_from_csv(csv_path, dataset, split_type=\"test\"):\n",
    "    \"\"\"\n",
    "    dataset: your image dataset, where dataset[i] -> (image, mask)\n",
    "    \"\"\"\n",
    "    folds_dict = load_folds_from_csv(csv_path)\n",
    "    folds = [folds_dict[k][split_type] for k in sorted(folds_dict.keys())]\n",
    "    proportions = [1 / len(folds)] * len(folds)\n",
    "\n",
    "    # Compute pixel counts (if not already available)\n",
    "    num_classes = dataset.num_classes\n",
    "    pixel_counts = np.zeros((len(dataset), num_classes))\n",
    "    print(\"Computing pixel class counts...\")\n",
    "    for i in range(len(dataset)):\n",
    "        _, mask = dataset[i]\n",
    "        pixel_counts[i] = np.bincount(mask.flatten(), minlength=num_classes)[:num_classes]\n",
    "    sd = sample_distribution(folds, proportions)\n",
    "    pld = pixel_label_distribution_from_pixel_counts(folds, pixel_counts)\n",
    "    lwd = label_wasserstein_distance_from_pixel_counts(folds, pixel_counts)\n",
    "\n",
    "    return {\"SD\": sd, \"PLD\": pld, \"LWD\": lwd}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "324ada78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pixel class counts...\n",
      "[[  3283. 120707. 196459. ...      0.      0.      0.]\n",
      " [  9314. 360995. 230940. ...      0.      0.      0.]\n",
      " [     0. 361004. 469380. ...      0.      0.      0.]\n",
      " ...\n",
      " [  1818. 328768. 409934. ...      0.      0.      0.]\n",
      " [     0. 169414. 467479. ...      0.      0.      0.]\n",
      " [     0. 131953. 430543. ...      0.      0.      0.]]\n",
      "📊 Sample Distribution (SD): 0.000000\n",
      "🎨 Pixel Label Distribution (PLD): 0.000329\n",
      "🌊 Label Wasserstein Distance (LWD): 0.008376\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_stratification_from_csv(\"split_log.csv\", dataset, split_type=\"test\")\n",
    "\n",
    "print(f\"📊 Sample Distribution (SD): {metrics['SD']:.6f}\")\n",
    "print(f\"🎨 Pixel Label Distribution (PLD): {metrics['PLD']:.6f}\")\n",
    "print(f\"🌊 Label Wasserstein Distance (LWD): {metrics['LWD']:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic-stratification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
